{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-b6GL2xcDSdTaliUfsgamQ8N9mGqwtLA","timestamp":1679305361855}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNPp8eHz0YsV","executionInfo":{"status":"ok","timestamp":1679507655505,"user_tz":-180,"elapsed":7458,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"e80b0689-7668-48fc-89b6-454829268837"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tflearn\n","  Downloading tflearn-0.5.0.tar.gz (107 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tflearn) (1.22.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from tflearn) (1.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from tflearn) (8.4.0)\n","Building wheels for collected packages: tflearn\n","  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=18416ce7ce0e0309fc33c93530ab5aaced7c26d2f78cd73697bf5c570a51e186\n","  Stored in directory: /root/.cache/pip/wheels/4a/d5/f8/9585b4a100c0fd73da204ee785457d67c85e1b9050f009a849\n","Successfully built tflearn\n","Installing collected packages: tflearn\n","Successfully installed tflearn-0.5.0\n"]}],"source":["!pip install tflearn"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt') #if in case tokenize sentences in words\n","from nltk.stem.lancaster import  LancasterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","import numpy as np\n","import tensorflow as tf\n","import tflearn\n","import random\n","import json\n","import pandas as pd"],"metadata":{"id":"rldLVW7G0Z3O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679507660690,"user_tz":-180,"elapsed":5202,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"7dfac5da-daef-4d93-87cb-a650c30f222e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"enEN_wLs0Z5x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679507689935,"user_tz":-180,"elapsed":29279,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"fa41bf60-ec41-4045-d1fc-c98b5e08582f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Import Data"],"metadata":{"id":"64qG54Kb1BWX"}},{"cell_type":"code","source":["data_dir = \"/content/drive/My Drive/CHATBOT/intents.json\"\n","intents = pd.read_json(data_dir)\n","intents.head()"],"metadata":{"id":"naqplo1X0Z-l","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1679507689936,"user_tz":-180,"elapsed":100,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"4d9baa80-d03b-4bfc-8be5-415590cc506e"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             intents\n","0  {'tag': 'greeting', 'patterns': ['Hi', 'Hey', ...\n","1  {'tag': 'morning', 'patterns': ['Good morning'...\n","2  {'tag': 'afternoon', 'patterns': ['Good aftern...\n","3  {'tag': 'evening', 'patterns': ['Good evening'...\n","4  {'tag': 'night', 'patterns': ['Good night'], '..."],"text/html":["\n","  <div id=\"df-4e47d9e8-a91c-4e0b-a4d3-d433d70fde2c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'tag': 'greeting', 'patterns': ['Hi', 'Hey', ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'tag': 'morning', 'patterns': ['Good morning'...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'tag': 'afternoon', 'patterns': ['Good aftern...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'tag': 'evening', 'patterns': ['Good evening'...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'tag': 'night', 'patterns': ['Good night'], '...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e47d9e8-a91c-4e0b-a4d3-d433d70fde2c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4e47d9e8-a91c-4e0b-a4d3-d433d70fde2c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4e47d9e8-a91c-4e0b-a4d3-d433d70fde2c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Tokenizing Words"],"metadata":{"id":"25odOJXY1JCE"}},{"cell_type":"code","source":["words = []\n","classes = []\n","documents = []\n","ignore = ['?']\n","#loop through each sentence in the intent's patterns\n","for intent in intents['intents']:\n","  for pattern in intent['patterns']:\n","    w = nltk.word_tokenize(pattern)\n","    words.extend(w)\n","    documents.append((w, intent['tag']))\n","    if intent['tag'] not in classes:\n","      classes.append(intent['tag'])"],"metadata":{"id":"KAOQlsGV1FBw","executionInfo":{"status":"ok","timestamp":1679507689937,"user_tz":-180,"elapsed":86,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Stemming"],"metadata":{"id":"UJ692UYt1VYf"}},{"cell_type":"code","source":["stemmer = LancasterStemmer()\n","\n","words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n","words = sorted(list(set(words)))\n","classes = sorted(list(set(classes)))\n","\n","print(len(documents),\"documents\")\n","print(len(classes), \"classes\", classes)\n","print(len(words), \"unique stemmed words\", words)"],"metadata":{"id":"d9gZVOr91FEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679507689937,"user_tz":-180,"elapsed":85,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"ae4fb917-9431-4d0f-8322-dcdd02081a48"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["276 documents\n","106 classes [' many issues', \"A friend of my child's father is sending him inappropriate content\", 'About a year ago I found out my husband had cheated on me', 'All I can do is cry and hate myself', 'Am I being picky when it comes to my boyfriend?', 'Am I going to be alone forever?', 'Am I somehow stressing myself out?', 'Am I unworthy of being in a meaningful relationship?', 'Can I change my feeling of being worthless to everyone?', 'Can i learn to be happy alone?', 'PTSD', 'about', 'afternoon', 'anxiety and stress', 'anxious', 'ask', 'better', 'break', 'casual', 'creation', 'cure', 'deal depression', 'deal with a break up', 'death', 'default', 'dep', 'depressed', 'done', 'evening', 'expectations', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greeting', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'nothing', 'pandora-useful', 'parents', 'problem', 'quit', 'repeat', 'sad', 'scared', 'schizophrenia', 'skill', 'sleep', 'social anxiety', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'treatment', 'ugly', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n","408 unique stemmed words ['!', \"'\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ',', '.', 'a', 'about', 'absolv', 'address', 'adult', 'adv', 'affect', 'afternoon', 'again', 'agree', 'al', 'almost', 'alon', 'alot', 'already', 'also', 'alway', 'am', 'an', 'and', 'ang', 'annoy', 'anoth', 'answ', 'anxy', 'any', 'anym', 'anyon', 'anyth', 'apathet', 'appear', 'approach', 'ar', 'around', 'as', 'ask', 'at', 'attack', 'au', 'avail', 'aw', 'away', 'back', 'bad', 'bar', 'be', 'becaus', 'becom', 'been', 'bef', 'being', 'believ', 'bet', 'between', 'block', 'bothersom', 'boyfriend', 'break', 'bring', 'brok', 'broth', 'burn', 'but', 'by', 'bye', 'ca', 'cal', 'can', 'car', 'caus', 'chang', 'che', 'check', 'child', 'childr', 'co-worker', 'com', 'commit', 'complet', 'connect', 'cont', 'contempl', 'continu', 'control', 'convint', 'could', 'crazy', 'cre', 'cur', 'dad', 'dant', 'daught', 'day', 'deal', 'decid', 'deep', 'defin', 'depress', 'deserv', 'did', 'die', 'died', 'diff', 'disord', 'divorc', 'do', 'doe', 'down', 'dumb', 'edg', 'els', 'empty', 'enough', 'ev', 'every', 'everyon', 'ex', 'exam', 'fact', 'famy', 'far', 'fath', 'feel', 'few', 'fiancã©', 'fin', 'find', 'fix', 'foc', 'for', 'forg', 'forget', 'forward', 'friend', 'from', 'get', 'girl-friend', 'girlfriend', 'giv', 'go', 'going', 'good', 'goodby', 'got', 'gre', 'group', 'guess', 'habar', 'had', 'hand', 'hap', 'happy', 'has', 'hat', 'hav', 'he', 'heal', 'heart', 'hello', 'help', 'her', 'hey', 'hi', 'him', 'his', 'hmmm', 'hol', 'how', 'howev', 'hurt', 'i', 'if', 'il', 'im', 'import', 'imposs', 'in', 'inappropry', 'inform', 'insomin', 'insomn', 'interest', 'into', 'involv', 'is', 'issu', 'it', 'jok', 'judg', 'just', 'k', 'kept', 'kil', 'know', 'last', 'lat', 'learn', 'left', 'let', 'lif', 'lik', 'ling', 'liv', 'loc', 'lon', 'look', 'lov', 'm', 'mad', 'maintain', 'maj', 'mak', 'many', 'me', 'mean', 'med', 'medit', 'men', 'ment', 'mind', 'mom', 'money', 'mor', 'morn', 'mov', 'much', 'my', 'myself', \"n't\", 'nam', 'nee', 'nev', 'new', 'nic', 'night', 'nightm', 'no', 'nobody', 'not', 'noth', 'now', 'num', 'of', 'oh', 'ok', 'okay', 'on', 'op', 'opt', 'or', 'oth', 'our', 'out', 'overcom', 'overwhelm', 'pain', 'pan', 'par', 'pass', 'past', 'peopl', 'pleas', 'poss', 'pract', 'prep', 'prev', 'prob', 'problem', 'profess', 'prop', 'ptsd', 'put', 'quest', 'quit', 'real', 'reciproc', 'recov', 'rel', 'rep', 'respect', 'respons', 'revoir', 'right', 'robot', 'sad', 'said', 'sas', 'say', 'sayonar', 'scar', 'schizophrenia', 'school', 'see', 'seem', 'send', 'sens', 'sent', 'should', 'shouldn', 'shut', 'sign', 'sist', 'sleep', 'slept', 'so', 'soc', 'som', 'someon', 'someth', 'sometim', 'sound', 'start', 'stay', 'stil', 'stress', 'stressed', 'stressing', 'struggling', 'stuck', 'stupid', 'suff', 'suicid', 'support', 'sur', 'sweet', 'symptom', 't', 'tak', 'talk', 'tel', 'than', 'thank', 'that', 'the', 'them', 'then', 'ther', 'therap', 'therapy', 'thes', 'they', 'thi', 'thing', 'think', 'thought', 'through', 'tim', 'tir', 'to', 'today', 'told', 'trauma', 'tre', 'tri', 'tru', 'trust', 'try', 'two', 'typ', 'ug', 'unacceiv', 'understand', 'unwel', 'up', 'us', 'useless', 've', 'very', 'video', 'want', 'warn', 'was', 'way', 'we', 'wel', 'wer', 'what', 'whatev', 'when', 'wher', 'which', 'who', 'why', 'wif', 'wil', 'wish', 'with', 'without', 'worry', 'worthless', 'would', 'wrong', 'yako', 'ye', 'yeah', 'year', 'yo', 'you', 'yourself']\n"]}]},{"cell_type":"markdown","source":["## Creating Training Data"],"metadata":{"id":"CiXB_1e51miK"}},{"cell_type":"code","source":["training = []\n","output = []\n","output_empty = [0] * len(classes)\n","\n","for doc in documents: \n","  bag = []\n","  pattern_words = doc[0]\n","  pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n","  for w in words:\n","    bag.append(1) if w in pattern_words else bag.append(0)\n","\n","  output_row = list(output_empty)\n","  output_row[classes.index(doc[1])] = 1\n","  training.append([bag,output_row])\n","\n","random.shuffle(training)\n","training = np.array(training)\n","\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])"],"metadata":{"id":"BCT1awWe1FGr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679507689938,"user_tz":-180,"elapsed":83,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"a01c470f-f1a8-4ae7-cb92-f636cb9fa264"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-ce4918b07244>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  training = np.array(training)\n"]}]},{"cell_type":"markdown","source":["## Creating Model & Training"],"metadata":{"id":"16rKH7Uc19WL"}},{"cell_type":"code","source":["tf.compat.v1.reset_default_graph()"],"metadata":{"id":"je1FK3QR2FhK","executionInfo":{"status":"ok","timestamp":1679507689939,"user_tz":-180,"elapsed":19,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# DNN\n","net = tflearn.input_data(shape=[None, len(train_x[0])])\n","net = tflearn.fully_connected(net, 10)\n","net = tflearn.fully_connected(net, 10)\n","net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n","net = tflearn.regression(net)"],"metadata":{"id":"mzBoqvol19wa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679507689940,"user_tz":-180,"elapsed":19,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"5caa7a05-c6cb-4fcf-8d67-5966a5577ec9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"]}]},{"cell_type":"code","source":["# # Dynamic RNN (LSTM)\n","# net = tflearn.input_data(shape=[None, len(train_x[0])])\n","# net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n","# net = tflearn.lstm(net, 128, dropout=0.8, dynamic=True)\n","# net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n","# net = tflearn.regression(net)"],"metadata":{"id":"dFk1zoau19yq","executionInfo":{"status":"ok","timestamp":1679507689941,"user_tz":-180,"elapsed":18,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"],"metadata":{"id":"dKzIKK9f7sGx","executionInfo":{"status":"ok","timestamp":1679507690446,"user_tz":-180,"elapsed":523,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model.fit(train_x, train_y, n_epoch = 1000, batch_size=8, show_metric=True)"],"metadata":{"id":"uSshjlvm191b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679509026809,"user_tz":-180,"elapsed":1336366,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"a26228a1-6caa-4d8e-9ef3-b4f8149c53d9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Step: 34999  | total loss: \u001b[1m\u001b[32m0.04819\u001b[0m\u001b[0m | time: 0.155s\n","| Adam | epoch: 1000 | loss: 0.04819 - acc: 0.9591 -- iter: 272/276\n","Training Step: 35000  | total loss: \u001b[1m\u001b[32m0.04339\u001b[0m\u001b[0m | time: 0.158s\n","| Adam | epoch: 1000 | loss: 0.04339 - acc: 0.9632 -- iter: 276/276\n","--\n"]}]},{"cell_type":"code","source":["model.save('/content/drive/My Drive/CHATBOT/model.tflearn')"],"metadata":{"id":"ghxIVlV2194-","executionInfo":{"status":"ok","timestamp":1679509026813,"user_tz":-180,"elapsed":96,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import pickle\n","pickle.dump({'words' : words, 'classes':classes, 'train_x': train_x, 'train_y' : train_y}, open(\"training_data\", \"wb\"))"],"metadata":{"id":"d3E3ocWt2aVR","executionInfo":{"status":"ok","timestamp":1679509026820,"user_tz":-180,"elapsed":57,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Chatbot Testing"],"metadata":{"id":"82d_SWVz2bkq"}},{"cell_type":"code","source":["data = pickle.load(open('training_data','rb'))\n","words = data['words']\n","classes = data['classes']\n","train_x = data['train_x']\n","train_y = data['train_y']\n","\n","model.load('/content/drive/My Drive/CHATBOT//model.tflearn')"],"metadata":{"id":"S683GYAd2aXt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1679509026824,"user_tz":-180,"elapsed":59,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}},"outputId":"fe4a8bd7-6b90-4515-fa7d-66610688ce5b"},"execution_count":15,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1362\u001b[0m                                       target_list, run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1453\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1454\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1455\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [106] rhs shape= [91]\n\t [[{{node save_1/Assign_19}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m         sess.run(self.saver_def.restore_op_name,\n\u001b[0m\u001b[1;32m   1416\u001b[0m                  {self.saver_def.filename_tensor_name: save_path})\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    969\u001b[0m                          run_metadata_ptr)\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1192\u001b[0m                              feed_dict_tensor, options, run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1372\u001b[0m                            run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1397\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'save_1/Assign_19' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 748, in __init__\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-11-4052b5557337>\", line 1, in <module>\n      model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n    File \"/usr/local/lib/python3.9/dist-packages/tflearn/models/dnn.py\", line 57, in __init__\n      self.trainer = Trainer(self.train_ops,\n    File \"/usr/local/lib/python3.9/dist-packages/tflearn/helpers/trainer.py\", line 149, in __init__\n      self.restorer = tf.train.Saver(\nNode: 'save_1/Assign_19'\nAssign requires shapes of both tensors to match. lhs shape= [106] rhs shape= [91]\n\t [[{{node save_1/Assign_19}}]]\n\nOriginal stack trace for 'save_1/Assign_19':\n  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 748, in __init__\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-4052b5557337>\", line 1, in <module>\n    model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n  File \"/usr/local/lib/python3.9/dist-packages/tflearn/models/dnn.py\", line 57, in __init__\n    self.trainer = Trainer(self.train_ops,\n  File \"/usr/local/lib/python3.9/dist-packages/tflearn/helpers/trainer.py\", line 149, in __init__\n    self.restorer = tf.train.Saver(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 931, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 943, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 971, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 540, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 383, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 83, in restore\n    return state_ops.assign(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/state_ops.py\", line 352, in assign\n    return gen_state_ops.assign(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 58, in assign\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n    ret = Operation(\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-22565206c5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Mental_Health//model.tflearn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model_file, weights_only, **optargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m                      \u001b[0mcreated\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrestored\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         self.predictor = Evaluator([self.net],\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, model_file, trainable_variable_only, variable_name_map, scope_for_restore, create_new_session, verbose)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrainable_variable_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestorer_trainvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1449\u001b[0m       \u001b[0;31m# There is a mismatch between the graph and the checkpoint being loaded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m       raise _wrap_restore_error_with_msg(\n\u001b[0m\u001b[1;32m   1452\u001b[0m           err, \"a mismatch between the current graph and the graph\")\n\u001b[1;32m   1453\u001b[0m     metrics.AddCheckpointReadDuration(\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nGraph execution error:\n\nDetected at node 'save_1/Assign_19' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 748, in __init__\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-11-4052b5557337>\", line 1, in <module>\n      model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n    File \"/usr/local/lib/python3.9/dist-packages/tflearn/models/dnn.py\", line 57, in __init__\n      self.trainer = Trainer(self.train_ops,\n    File \"/usr/local/lib/python3.9/dist-packages/tflearn/helpers/trainer.py\", line 149, in __init__\n      self.restorer = tf.train.Saver(\nNode: 'save_1/Assign_19'\nAssign requires shapes of both tensors to match. lhs shape= [106] rhs shape= [91]\n\t [[{{node save_1/Assign_19}}]]\n\nOriginal stack trace for 'save_1/Assign_19':\n  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 748, in __init__\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-4052b5557337>\", line 1, in <module>\n    model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n  File \"/usr/local/lib/python3.9/dist-packages/tflearn/models/dnn.py\", line 57, in __init__\n    self.trainer = Trainer(self.train_ops,\n  File \"/usr/local/lib/python3.9/dist-packages/tflearn/helpers/trainer.py\", line 149, in __init__\n    self.restorer = tf.train.Saver(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 931, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 943, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 971, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 540, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saver.py\", line 383, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 83, in restore\n    return state_ops.assign(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/state_ops.py\", line 352, in assign\n    return gen_state_ops.assign(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 58, in assign\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n    ret = Operation(\n"]}]},{"cell_type":"markdown","source":["## Creating methods for calling chatbot"],"metadata":{"id":"jxfhT1J_2sZf"}},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","def clean_up_sentence(sentence):\n","    sentence_words = nltk.word_tokenize(sentence)\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","  \n","def bow(sentence, words, show_details = False):\n","  sentence_words = clean_up_sentence(sentence)\n","  bag = [0]*len(words)\n","  for s in sentence_words:\n","    for i,w in enumerate(words):\n","      if w==s:\n","        bag[i] = 1\n","        if show_details:\n","          print('found in bag: %s' % w)\n","  return (np.array(bag))"],"metadata":{"id":"lH6nnZNY2aak","executionInfo":{"status":"aborted","timestamp":1679508020514,"user_tz":-180,"elapsed":376890,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context = {}\n","\n","ERROR_THRESHOLD = 0.25\n","def classify(sentence):\n","    # generate probabilities from the model\n","    results = model.predict([bow(sentence, words)])[0]\n","    # filter out predictions below a threshold\n","    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append((classes[r[0]], r[1]))\n","    # return tuple of intent and probability\n","    return return_list\n","\n","def response(sentence, userID='123', show_details=False):\n","    results = classify(sentence)\n","    # if we have a classification then find the matching intent tag\n","    if results:\n","        # loop as long as there are matches to process\n","        while results:\n","            for i in intents['intents']:\n","                # find a tag matching the first result\n","                if i['tag'] == results[0][0]:\n","                    # set context for this intent if necessary\n","                    if 'context_set' in i:\n","                        if show_details: print ('context:', i['context_set'])\n","                        context[userID] = i['context_set']\n","\n","                    # check if this intent is contextual and applies to this user's conversation\n","                    if not 'context_filter' in i or \\\n","                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n","                        if show_details: print ('tag:', i['tag'])\n","                        # a random response from the intent\n","                        return random.choice(i['responses'])\n","\n","            results.pop(0)"],"metadata":{"id":"jktu3G872ac7","executionInfo":{"status":"aborted","timestamp":1679508020518,"user_tz":-180,"elapsed":376881,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Testing Chatbot"],"metadata":{"id":"1nZOEw9w2_Xq"}},{"cell_type":"code","source":["print(response(\"What is your name?\"))"],"metadata":{"id":"ZkcCMcO82agp","executionInfo":{"status":"aborted","timestamp":1679508020521,"user_tz":-180,"elapsed":376873,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define a function to start the chatbot\n","stemmer = LancasterStemmer()\n","def chatbot():\n","    print(\"Start talking with the chatbot (type quit to stop)!\")\n","    while True:\n","        inp = input(\"You: \")\n","        if inp.lower() == \"quit\":\n","            break\n","        response_output = response(inp)\n","        print(\"Bot:\", response_output)\n","\n","# start the chatbot\n","chatbot()"],"metadata":{"id":"FLJT44M90aBK","executionInfo":{"status":"aborted","timestamp":1679508020523,"user_tz":-180,"elapsed":376859,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QzkvlgVLem9C","executionInfo":{"status":"aborted","timestamp":1679508020524,"user_tz":-180,"elapsed":376841,"user":{"displayName":"Evans Kibet","userId":"02952049636202432824"}}},"execution_count":null,"outputs":[]}]}